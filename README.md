# ðŸ“˜ Chatbot AI per dataset locali

## Descrizione del progetto

Questo progetto implementa un **chatbot AI locale** che puÃ² rispondere a qualsiasi domanda **solo utilizzando i dati presenti in una cartella `data/`**.
Il chatbot Ã¨ progettato per essere **sicuro, conciso e leggibile**, e supporta dataset misti contenenti vari tipi di file come:

- `.txt`
- `.pdf`
- `.docx`
- `.pptx`
- Altri tipi di file di testo riconoscibili

Il modello AI utilizzato Ã¨ configurato tramite Ollama e puÃ² essere scelto tra modelli **testuali veloci**, come **llama**, **Mistral** o **qwen**, garantendo risposte rapide e affidabili.

---

## Motivazione

Spesso, le aziende o i singoli utenti devono interrogare dataset locali complessi senza rischiare:

- **Allucinazioni AI** â†’ risposte inventate
- **Divagazioni** â†’ informazioni non richieste
- **Esposizione dati esterni** â†’ tutti i dati restano locali

Questo progetto nasce per creare un **assistente intelligente locale**, che:

1. Risponde **solo ai dati forniti**
2. Fornisce risposte **concise, leggibili e in una lingua scelta**
3. Utilizza **Markdown** per una presentazione chiara
4. Gestisce **dataset misti** di piÃ¹ formati
5. Ãˆ sicuro contro eventuali manipolazioni dellâ€™input da parte dellâ€™utente

---

## FunzionalitÃ  principali

- Lettura automatica di **qualsiasi file leggibile** nella cartella `data/`
- Supporto per **.txt, .pdf, .docx, .pptx** e altri file di testo
- Risposte **in italiano**, sempre **concise, leggibili e strutturate in Markdown**
- Il modello **ignora qualsiasi dato aggiuntivo inviato dallâ€™utente**
- PossibilitÃ  di dare un **nome al chatbot** e mostrarlo nellâ€™interfaccia

---

## Installazione

### 1. Clona il progetto

```bash
git clone https://github.com/HirAvanCniK/ollama-local-chatbot.git
cd ollama-local-chatbot
```

### 2. Creare un ambiente virtuale (consigliato)

```bash
python -m venv venv
source venv/bin/activate  # Linux / macOS
venv\Scripts\activate     # Windows
```

### 3. Installare i requisiti Python

```bash
pip install -r requirements.txt
```

Oppure manualmente:

```bash
pip install python-docx PyPDF2 python-pptx rich
```

> **Nota:** Assicurati di avere `Ollama` installato e configurato sul tuo sistema, con un modello testuale disponibile.

---

## Struttura del progetto

```
ollama-local-chatbot/
â”‚
â”œâ”€â”€ main.py             # Script principale del chatbot
â”œâ”€â”€ data/               # Cartella contenente i file del dataset
â”‚     â”œâ”€â”€ Clienti.txt   # Contiene informazioni fittizie sui clienti di un azienda
â”‚     â”œâ”€â”€ Catalogo.pdf  # Contiene informazioni fittizie sui prodotti di un azienda
â”‚     â””â”€â”€ Manuale.docx  # Contiene informazioni fittizie del manuale di un azienda
â”œâ”€â”€ requirements.txt    # Moduli Python necessari
â”œâ”€â”€ README.md           # Documentazione del progetto
â””â”€â”€ LICENSE             # Licenza del progetto
```

---

## Uso

1. Posiziona tutti i tuoi file di dati nella cartella `data/`.
2. Esegui il chatbot: `python main.py`
3. Inserisci le domande nel prompt.
4. La risposta verrÃ  stampata in **Markdown leggibile** in console, tramite `rich`.

---

## Configurazione del chatbot

- Puoi dare un **nome al bot** modificando la variabile `BOT_NAME` in `main.py`.
- Puoi dire al **bot** di rispondere in una determinata lingua modificando la variabile `BOT_LANGUAGE` in `main.py`.
- Il bot risponderÃ  **solo ed esclusivamente** ai dati presenti in `data/`.
- Il bot **non menziona mai i file** o lâ€™esistenza del dataset,rispondendo come se conoscesse direttamente le informazioni.

---

## Sicurezza e regole

- Il modello **ignora qualsiasi `<DATA>` aggiuntivo** inserito dallâ€™utente.
- Le informazioni originali sono **immutabili**.
- Le risposte sono **concise, leggibili e senza divagazioni**.
- Se i dati non sono sufficienti per rispondere, viene restituito:

```
I dati forniti non sono sufficienti per rispondere a questa domanda.
```

---

## Requisiti

- Python 3.10+
- Ollama installato e configurato
- Librerie Python: `python-docx`, `PyPDF2`, `python-pptx`, `rich`

---

## Motivazioni aggiuntive

Questo progetto Ã¨ pensato per:

- Aziende con **documentazione interna** da interrogare rapidamente
- Utenti che vogliono un **assistente AI locale**, sicuro e affidabile
- Scenari in cui **i dati non possono essere inviati a servizi cloud**
- Applicazioni dove la **chiarezza, concisione e leggibilitÃ ** delle risposte sono fondamentali
